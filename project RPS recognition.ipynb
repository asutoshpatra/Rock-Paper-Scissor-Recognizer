{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense,MaxPool2D,Dropout,Flatten,Conv2D,GlobalAveragePooling2D,Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from random import choice,shuffle\n",
    "from scipy import stats as st\n",
    "\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_data(num_samples):\n",
    "    \n",
    "    global rock, paper, scissor, nothing\n",
    "    \n",
    "    # Initialize the camera\n",
    "    cap = cv2.VideoCapture(0,  cv2.CAP_DSHOW)\n",
    "\n",
    "    # trigger tells us when to start recording\n",
    "    trigger = False\n",
    "    \n",
    "    # Counter keeps count of the number of samples collected\n",
    "    counter = 0\n",
    "    \n",
    "    # This the ROI size, the size of images saved will be box_size -10\n",
    "    box_size = 234\n",
    "    \n",
    "    # Getting the width of the frame from the camera properties\n",
    "    width = int(cap.get(3))\n",
    "\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        # Read frame by frame\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Flip the frame laterally\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        # Break the loop if there is trouble  reading the frame.\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        # If counter is equal to the number samples then reset triger and the counter\n",
    "        if counter == num_samples:\n",
    "            trigger = not trigger\n",
    "            counter = 0\n",
    "        \n",
    "        # Define ROI for capturing samples\n",
    "        cv2.rectangle(frame, (width - box_size, 0), (width, box_size), (0, 250, 150), 2)\n",
    "        \n",
    "        # Make a resizable window.\n",
    "        cv2.namedWindow(\"Collecting images\", cv2.WINDOW_NORMAL)\n",
    "        \n",
    "        \n",
    "        # If trigger is True than start capturing the samples\n",
    "        if trigger:\n",
    "            \n",
    "            # Grab only slected roi\n",
    "            roi = frame[5: box_size-5 , width-box_size + 5: width -5]\n",
    "            \n",
    "            # Append the roi and class name to the list with the selected class_name\n",
    "            eval(class_name).append([roi, class_name])\n",
    "                                    \n",
    "            # Increment the counter \n",
    "            counter += 1 \n",
    "        \n",
    "            # Text for the counter\n",
    "            text = \"Collected Samples of {}: {}\".format(class_name, counter)\n",
    "            \n",
    "        else:\n",
    "            text = \"Press 'r'= rock , 'p' = paper, 's' = scissor , 'n' = nothing, 'q' = quit \"\n",
    "        \n",
    "        # Show the counter on the imaege\n",
    "        cv2.putText(frame, text, (3, 350), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "        \n",
    "        # Display the window\n",
    "        cv2.imshow(\"Collecting images\", frame)\n",
    "        \n",
    "        # Wait 1 ms\n",
    "        k = cv2.waitKey(1)\n",
    "        \n",
    "        # If user press 'r' than set the path for rock directoryq\n",
    "        if k == ord('r'):\n",
    "            \n",
    "            # Trigger the variable inorder to capture the samples\n",
    "            trigger = not trigger\n",
    "            class_name = 'rock'\n",
    "            rock = []\n",
    "           \n",
    "            \n",
    "        # If user press 'p' then class_name is set to paper and trigger set to True  \n",
    "        if k == ord('p'):\n",
    "            trigger = not trigger\n",
    "            class_name = 'paper'\n",
    "            paper = []\n",
    "        \n",
    "        # If user press 's' then class_name is set to scissor and trigger set to True  \n",
    "        if k == ord('s'):\n",
    "            trigger = not trigger\n",
    "            class_name = 'scissor'\n",
    "            scissor = []\n",
    "                    \n",
    "        # If user press 's' then class_name is set to nothing and trigger set to True\n",
    "        if k == ord('n'):\n",
    "            trigger = not trigger\n",
    "            class_name = 'nothing'\n",
    "            nothing = []\n",
    "        \n",
    "        # Exit if user presses 'q'\n",
    "        if k == ord('q'):\n",
    "            break\n",
    "            \n",
    "    #  Release the camera and destroy the window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_samples = 100\n",
    "gather_data(no_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rock' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-088caef787d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Iterate for each class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mclass_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meach_list\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpaper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscissor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnothing\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Get 8 random indexes, since we will be showing 8 examples of each class.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rock' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the figure size\n",
    "plt.figure(figsize=[30,20])\n",
    "\n",
    "# Set the rows and columns\n",
    "rows, cols = 4, 8\n",
    "\n",
    "# Iterate for each class\n",
    "for class_index, each_list in enumerate([rock, paper, scissor,nothing]):\n",
    "    \n",
    "    # Get 8 random indexes, since we will be showing 8 examples of each class.\n",
    "    r = np.random.randint(no_of_samples, size=8);\n",
    "    \n",
    "    # Plot the examples\n",
    "    for i, example_index in enumerate(r,1):\n",
    "        plt.subplot(rows,cols,class_index*cols + i );plt.imshow(each_list[example_index][0][:,:,::-1]);plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the labels of all classes together\n",
    "labels = [tupl[1] for tupl in rock] + [tupl[1] for tupl in paper] + [tupl[1] for tupl in scissor] +[tupl[1] for tupl in nothing]\n",
    "\n",
    "# Combine the images of all classes together\n",
    "images = [tupl[0] for tupl in rock] + [tupl[0] for tupl in paper] + [tupl[0] for tupl in scissor] +[tupl[0] for tupl in nothing]\n",
    "\n",
    "# Normalize the images by dividing by 255, now our images are in range 0-1. This will help in training.\n",
    "images = np.array(images, dtype=\"float\") / 255.0\n",
    "\n",
    "# Print out the total number of labels and images.\n",
    "print('Total images: {} , Total Labels: {}'.format(len(labels), len(images)))\n",
    "\n",
    "# Create an encoder Object\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Convert Lablels to integers. i.e. nothing = 0, paper = 1, rock = 2, scissor = 3 (mapping is done in alphabatical order)\n",
    "Int_labels = encoder.fit_transform(labels)\n",
    "\n",
    "# Now the convert the integer labels into one hot format. i.e. 0 = [1,0,0,0]  etc.\n",
    "one_hot_labels = to_categorical(Int_labels, 4)\n",
    "\n",
    "# Now we're splitting the data, 75% for training and 25% for testing.\n",
    "(trainX, testX, trainY, testY) = train_test_split(images, one_hot_labels, test_size=0.25, random_state=50)\n",
    "\n",
    "# Empty memory from RAM\n",
    "images = []\n",
    "\n",
    "\n",
    "# This can further free up memory from RAM but be careful, if you won't be able to chage split % after this.\n",
    "# rock, paper, scissor = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the input size which our model accepts.\n",
    "image_size = 224\n",
    "\n",
    "# Loading pre-trained NASNETMobile Model without the head by doing include_top = False\n",
    "N_mobile = tf.keras.applications.NASNetMobile( input_shape=(image_size, image_size, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "# Freeze the whole model \n",
    "N_mobile.trainable = False\n",
    "    \n",
    "# Adding our own custom head\n",
    "# Start by taking the output feature maps from NASNETMobile\n",
    "x = N_mobile.output\n",
    "\n",
    "# Convert to a single dimensional vector by Global Average Pooling. \n",
    "# We could also use Flatten()(x) GAP is more effective reduces params and controls overfitting.\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Adding a dense layer with 512 units\n",
    "x = Dense(712, activation='relu')(x) \n",
    "\n",
    "# Dropout 20% of the activations, helps reduces overfitting\n",
    "x = Dropout(0.40)(x)\n",
    "\n",
    "# The fianl layer will contain 4 output units (no of units = no of classes) with softmax function.\n",
    "preds = Dense(4,activation='softmax')(x) \n",
    "\n",
    "# Construct the full model\n",
    "model = Model(inputs=N_mobile.input, outputs=preds)\n",
    "\n",
    "# Check the number of layers in the final Model\n",
    "print (\"Number of Layers in Model: {}\".format(len(model.layers[:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding transformations that I know would help, you can feel free to add more.\n",
    "# I'm doing horizontal_flip = False, incase you aren't sure which hand you would be using you can make that True.\n",
    "\n",
    "augment = ImageDataGenerator( \n",
    "    \n",
    "        rotation_range=30,\n",
    "        zoom_range=0.25,\n",
    "        width_shift_range=0.10,\n",
    "        height_shift_range=0.10,\n",
    "        shear_range=0.10,\n",
    "        horizontal_flip=False,    \n",
    "        fill_mode=\"nearest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batchsize according to your system\n",
    "epochs = 15\n",
    "batchsize = 20\n",
    "\n",
    "# Start training\n",
    "history = model.fit(x=augment.flow(trainX, trainY, batch_size=batchsize), validation_data=(testX, testY), \n",
    "steps_per_epoch= len(trainX) // batchsize, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"rps4.h5\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"rps4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list will be used to map probabilities to class names, Label names are in alphabatical order.\n",
    "label_names = ['nothing', 'paper', 'rock', 'scissor']\n",
    "\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "box_size = 234\n",
    "width = int(cap.get(3))\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    frame = cv2.flip(frame, 1)\n",
    "           \n",
    "    cv2.rectangle(frame, (width - box_size, 0), (width, box_size), (0, 250, 150), 2)\n",
    "        \n",
    "    cv2.namedWindow(\"Rock Paper Scissors\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "    roi = frame[5: box_size-5 , width-box_size + 5: width -5]\n",
    "    \n",
    "    # Normalize the image like we did in the preprocessing step, also convert float64 array.\n",
    "    roi = np.array([roi]).astype('float64') / 255.0\n",
    " \n",
    "    # Get model's prediction.\n",
    "    pred = model.predict(roi)\n",
    "    \n",
    "    # Get the index of the target class.\n",
    "    target_index = np.argmax(pred[0])\n",
    "\n",
    "    # Get the probability of the target class\n",
    "    prob = np.max(pred[0])\n",
    "\n",
    "    # Show results\n",
    "    cv2.putText(frame, \"prediction: {} {:.2f}%\".format(label_names[np.argmax(pred[0])], prob*100 ),\n",
    "                (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.90, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow(\"Rock Paper Scissors\", frame)\n",
    "    #cv2.putText(frame, \"Press 'r' to collect rock samples, 'p' for paper, 's' for scissor , 'n' for nothing and 'q' to quit\",(10, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.90, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    text = \"Press 'r' to collect rock samples, 'p' for paper, 's' for scissor , 'n' for nothing and 'q' to quit \"\n",
    "    \n",
    "   \n",
    "    k = cv2.waitKey(1)\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
